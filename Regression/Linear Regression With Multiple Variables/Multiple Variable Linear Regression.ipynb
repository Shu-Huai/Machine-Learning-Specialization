{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 可选实验室：多变量线性回归\n",
    "\n",
    "在本实验中，您将扩展数据结构和以前开发的例程以支持多种功能。更新了一些例程，使实验室显得冗长，但它对以前的例程进行了细微调整，使其可以快速回顾。\n",
    "\n",
    "# 大纲\n",
    "\n",
    "- [1.1 目标]()\n",
    "- [1.2 工具]()\n",
    "- [1.3 表示法]()\n",
    "- [2 问题陈述]()\n",
    "- [&nbsp;&nbsp;2.1 矩阵X包含我们的示例]()\n",
    "- [&nbsp;&nbsp;2.2 参数向量w, b]()\n",
    "- [3 多变量模型预测]()\n",
    "- [&nbsp;&nbsp;3.1 逐个元素的单预测]()\n",
    "- [&nbsp;&nbsp;3.2 单预测，向量]()\n",
    "- [4 多个变量的计算成本]()\n",
    "- [5 个多变量梯度下降]()\n",
    "- [5.1 计算多变量梯度]()\n",
    "- [5.2 多变量梯度下降]()\n",
    "- [6 恭喜]()"
   ],
   "id": "7033a0c36a1bf756"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.1 目标\n",
    "- 扩展我们的回归模型例程以支持多种功能\n",
    "  - 扩展数据结构以支持多种功能\n",
    "  - 重写预测、成本和梯度例程以支持多种功能\n",
    "  - 利用NumPy`np.dot`对其实现进行矢量化，以提高速度和简单性"
   ],
   "id": "c038ac8ee6ea0d94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.2 工具\n",
    "在本实验中，我们将利用：\n",
    "- NumPy，一个流行的科学计算库\n",
    "- Matplotlib，一个流行的绘制数据的库"
   ],
   "id": "8ed80ee4da9ec205"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.308064Z",
     "start_time": "2024-05-12T14:42:44.295554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy, math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('deeplearning.mplstyle')\n",
    "np.set_printoptions(precision=2)"
   ],
   "id": "efb699ccbd320d7c",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1.3 符号\n",
    "\n",
    "以下是您将遇到的一些符号的摘要，并针对多个功能进行了更新。\n",
    "\n",
    "| 一般表示法                                | 描述                                                                                                                            | Python（如果适用）  |\n",
    "|:-------------------------------------|:------------------------------------------------------------------------------------------------------------------------------|---------------|\n",
    "| $a$                                  | 标量，非粗体                                                                                                                        |               |\n",
    "| $\\mathbf{a}$                         | 矢量，粗体                                                                                                                         |               |\n",
    "| $\\mathbf{A}$                         | 矩阵，粗体大写                                                                                                                       |               |\n",
    "| **回归**                               |                                                                                                                               |               | |\n",
    "| $\\mathbf{X}$                         | 训练示例 maxtrix                                                                                                                  | `X_train`     |\n",
    "| $\\mathbf{y}$                         | 训练示例目标                                                                                                                        | `y_train`     |\n",
    "| $\\mathbf{x}^{(i)}$, $y^{(i)}$        | $i_{th}$训练示例                                                                                                                  | `X[i]`，`y[i]` |\n",
    "| 米                                    | 训练样本数量                                                                                                                        | `米`           |\n",
    "| n                                    | 每个示例中的特征数量                                                                                                                    | `n`           |\n",
    "| $\\mathbf{w}$                         | 参数：重量，                                                                                                                        | `w`           |\n",
    "| $b$                                  | 参数：偏差                                                                                                                         | `b`           |\n",
    "| $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$ | 由 $\\mathbf{w},b$ 参数化的 $\\mathbf{x^{(i)}}$ 处的模型评估结果：$f_{\\mathbf{w},b}(\\mathbf{x}^ {(i)}) = \\mathbf{w} \\cdot \\mathbf{x}^{(i)}+b$ | `f_wb`        |"
   ],
   "id": "b1ab607fff4d7cdf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#2 问题陈述\n",
    "\n",
    "您将使用房价预测的激励示例。训练数据集包含三个示例，具有四个特征（大小、卧室、楼层和年龄），如下表所示。请注意，与早期的实验室不同，尺寸单位为平方英尺，而不是1000平方英尺。这会导致一个问题，您将在下一个实验中解决该问题！\n",
    "\n",
    "| 尺寸（平方英尺） | 卧室数量 | 楼层数 | 家庭时代 | 价格（千元） |\n",
    "|----------|------|-----|------|--------|\n",
    "| 2104     | 5    | 1   | 45   | 460    | \n",
    "| 1416     | 3    | 2   | 40   | 232    | \n",
    "| 852      | 2    | 1   | 35   | 178    |\n",
    "\n",
    "您将使用这些值构建线性回归模型，以便您可以预测其他房屋的价格。例如，一套1200平方英尺、3间卧室、1层、40年的房子。\n",
    "\n",
    "请运行以下代码单元来创建`X_train`和`y_train`变量。"
   ],
   "id": "408235ea17bae3dc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.339575Z",
     "start_time": "2024-05-12T14:42:44.327565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = np.array([[2104, 5, 1, 45], [1416, 3, 2, 40], [852, 2, 1, 35]])\n",
    "y_train = np.array([460, 232, 178])"
   ],
   "id": "e2d0c23a47975ff",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 包含我们示例的矩阵X\n",
    "\n",
    "与上表类似，示例存储在NumPy矩阵`X_train`中。矩阵的每一行代表一个示例。当您有$m$个训练样本（在我们的示例中$m$为3个），并且有$n$个特征（在我们的示例中为4个）时，$\\mathbf{X}$是一个维度为（$m$, $n$）（m行，n列）。\n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{pmatrix}\n",
    " x^{(0)}_0 & x^{(0)}_1 & \\cdots & x^{(0)}_{n-1} \\\\ \n",
    " x^{(1)}_0 & x^{(1)}_1 & \\cdots & x^{(1)}_{n-1} \\\\\n",
    " \\cdots \\\\\n",
    " x^{(m-1)}_0 & x^{(m-1)}_1 & \\cdots & x^{(m-1)}_{n-1} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "符号：\n",
    "- $\\mathbf{x}^{(i)}$是包含示例i的向量。$\\mathbf{x}^{(i)}$$=(x^{(i)}_0,x^{(i)}_1,\\cdots,x^{(i)}_{n-1})$\n",
    "- $x^{(i)}_j$是示例i中的元素j。括号中的上标表示示例编号，下标表示元素。\n",
    "\n",
    "显示输入数据。"
   ],
   "id": "8c3bd32db0f0fc11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.354589Z",
     "start_time": "2024-05-12T14:42:44.341074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"X Shape: {X_train.shape}, X Type:{type(X_train)})\")\n",
    "print(X_train)\n",
    "print(f\"y Shape: {y_train.shape}, y Type:{type(y_train)})\")\n",
    "print(y_train)"
   ],
   "id": "70e61794564d7f6d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 参数向量w，b\n",
    "\n",
    "* $\\mathbf{w}$是一个包含$n$个元素的向量。\n",
    "   - 每个元素包含与一个特征相关的参数。\n",
    "   - 在我们的数据集中，n是4。\n",
    "   - 理论上，我们将其绘制为列向量\n",
    "\n",
    "$$\\mathbf{w} = \\begin{pmatrix}\n",
    "w_0 \\\\ \n",
    "w_1 \\\\\n",
    "\\cdots\\\\\n",
    "w_{n-1}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "* $b$是标量参数。"
   ],
   "id": "79dff58cfa5e0c3a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "为了演示，$\\mathbf{w}$和$b$将加载一些接近最佳值的初始选定值。$\\mathbf{w}$是一个一维NumPy向量。",
   "id": "3cfa2664d10cdd8c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.370096Z",
     "start_time": "2024-05-12T14:42:44.355589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b_init = 785.1811367994083\n",
    "w_init = np.array([0.39133535, 18.75376741, -53.36032453, -26.42131618])\n",
    "print(f\"w_init shape: {w_init.shape}, b_init type: {type(b_init)}\")"
   ],
   "id": "1ea5f3cce77cb8ea",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3 多变量模型预测\n",
    "具有多个变量的模型预测由线性模型给出：\n",
    "\n",
    "$$f_{\\mathbf{w},b}(\\mathbf{x})=w_0x_0+w_1x_1+\\cdots +w_{n-1}x_{n-1}+b\\tag{1}$$\n",
    "\n",
    "或用向量表示法：\n",
    "\n",
    "$$f_{\\mathbf{w},b}(\\mathbf{x})=\\mathbf{w}\\cdot\\mathbf{x}+b\\tag{2}$$\n",
    "\n",
    "其中$\\cdot$是向量`点积`\n",
    "\n",
    "为了演示点积，我们将使用（1）和（2）来实现预测。"
   ],
   "id": "a006369f2c768b62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.1 逐个元素的单预测\n",
    "\n",
    "我们之前的预测将一个特征值乘以一个参数，并添加一个偏差参数。我们之前对多个特征的预测实现的直接扩展是使用每个元素上的循环来实现上面的（1），与其参数执行乘法，然后在最后添加偏差参数。"
   ],
   "id": "db68bb141b272211"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.385596Z",
     "start_time": "2024-05-12T14:42:44.371596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_single_loop(x, w, b):\n",
    "    n = x.shape[0]\n",
    "    p = 0\n",
    "    for i in range(n):\n",
    "        p_i = x[i] * w[i]\n",
    "        p = p + p_i\n",
    "    p = p + b\n",
    "    return p"
   ],
   "id": "fff69cded89dcc18",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.401104Z",
     "start_time": "2024-05-12T14:42:44.386596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_vec = X_train[0, :]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "f_wb = predict_single_loop(x_vec, w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ],
   "id": "ea3521f2fd1f1a76",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "注意`x_vec`的形状。 它是一个具有4个元素(4,)的一维NumPy向量。 结果`f_wb`是一个标量。",
   "id": "5c67c92635fa2591"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3.2 单次预测，向量\n",
    "\n",
    "注意，上面的等式（1）可以使用上面（2）中的点积来实现。我们可以利用向量运算来加速预测。\n",
    "\n",
    "回想一下Python/Numpy实验室，NumPy`np.dot()`[[link](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)]可用于执行向量点积。"
   ],
   "id": "c59241a57a2a3207"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.417116Z",
     "start_time": "2024-05-12T14:42:44.402605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict(x, w, b):\n",
    "    p = np.dot(x, w) + b\n",
    "    return p"
   ],
   "id": "2ee8885c013f2e28",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.432627Z",
     "start_time": "2024-05-12T14:42:44.418620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_vec = X_train[0, :]\n",
    "print(f\"x_vec shape {x_vec.shape}, x_vec value: {x_vec}\")\n",
    "f_wb = predict(x_vec, w_init, b_init)\n",
    "print(f\"f_wb shape {f_wb.shape}, prediction: {f_wb}\")"
   ],
   "id": "e1899a332bbddca",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "结果和形状与使用循环的先前版本相同。今后，`np.dot`将用于这些操作。该预测现在是一个单一的陈述。大多数例程将直接实现它，而不是调用单独的预测例程。",
   "id": "8fa86e518a98cd7e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4 计算多变量成本\n",
    "\n",
    "多变量成本函数$J(\\mathbf{w},b)$的方程为：\n",
    "\n",
    "$$J(\\mathbf{w},b)=\\frac{1}{2m}\\sum\\limits_{i = 0}^{m-1}(f_{\\mathbf{w},b}(\\mathbf {x}^{(i)})-y^{(i)})^2\\tag{3}$$\n",
    "\n",
    "在哪里：\n",
    "\n",
    "$$f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})=\\mathbf{w}\\cdot\\mathbf{x}^{(i)}+b\\tag{4}$$\n",
    "\n",
    "与之前的实验相反，$\\mathbf{w}$和$\\mathbf{x}^{(i)}$是向量而不是支持多个特征的标量。"
   ],
   "id": "3af6a002240e884a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "下面是等式（3）和（4）的实现。请注意，这使用了*本课程的标准模式*，其中使用了所有`m`示例的for循环。",
   "id": "a2f7bf9ac21040e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.448132Z",
     "start_time": "2024-05-12T14:42:44.433627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_cost(x, y, w, b):\n",
    "    m = x.shape[0]\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        f_wb_i = np.dot(x[i], w) + b\n",
    "        cost = cost + (f_wb_i - y[i]) ** 2\n",
    "    cost = cost / (2 * m)\n",
    "    return cost"
   ],
   "id": "890697f3d1ede74b",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.463647Z",
     "start_time": "2024-05-12T14:42:44.450633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cost = compute_cost(X_train, y_train, w_init, b_init)\n",
    "print(f'最佳成本：{cost}')"
   ],
   "id": "84cecfadd05246cb",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**预期结果**：最佳成本w：1.5578904045996674e-12",
   "id": "885d60054d4bd79d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 5 多变量梯度下降\n",
    "\n",
    "多变量的梯度下降：\n",
    "\n",
    "重复直到收敛\n",
    "\n",
    "$$w_j=w_j-\\alpha\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}\\tag{5}\\;\\text{for j=0,1,\\cdots,n-1}$$\n",
    "$$b=b-\\alpha\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$$\n",
    "\n",
    "其中，n是特征数量，参数$w_j$、$b$同时更新，其中\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)})x_{j}^{(i)} \\tag{6}  \\\\\n",
    "\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{\\mathbf{w},b}(\\mathbf{x}^{(i)}) - y^{(i)}) \\tag{7}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* m是数据集中训练样本的数量\n",
    "\n",
    "* $f_{\\mathbf{w},b}(\\mathbf{x}^{(i)})$是模型的预测，而$y^{(i)}$是目标值"
   ],
   "id": "7d0ec4d8219fdcc9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.1 计算多变量梯度\n",
    "\n",
    "计算方程（6）和（7）的实现如下。有很多方法可以实现这一点。在这个版本中，有一个\n",
    "\n",
    "- 所有m个示例的外循环。\n",
    "     - $\\frac{\\partial J(\\mathbf{w},b)}{\\partial b}$的例子可以直接计算并累加\n",
    "     - 在所有n个特征的第二个循环中：\n",
    "         - 对每个$w_j$计算$\\frac{\\partial J(\\mathbf{w},b)}{\\partial w_j}$。"
   ],
   "id": "d2b7f71c832fdae0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.479148Z",
     "start_time": "2024-05-12T14:42:44.465147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_gradient(x, y, w, b):\n",
    "    m, n = x.shape\n",
    "    dj_dw = np.zeros((n,))\n",
    "    dj_db = 0.\n",
    "    for i in range(m):\n",
    "        err = (np.dot(x[i], w) + b) - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + err * x[i, j]\n",
    "        dj_db = dj_db + err\n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    return dj_db, dj_dw"
   ],
   "id": "f3b54ce19dcbbc39",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.494654Z",
     "start_time": "2024-05-12T14:42:44.480148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tmp_dj_db, tmp_dj_dw = compute_gradient(X_train, y_train, w_init, b_init)\n",
    "print(f'dj_db初始w、b：{tmp_dj_db}')\n",
    "print(f'dj_dw初始w、b：{tmp_dj_dw}')"
   ],
   "id": "243e63bab323ccb7",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**预期结果**：\n",
    "\n",
    "dj_db初始w、b：-1.6739251122999121e-06\n",
    "\n",
    "dj_dw初始w、b：[-2.73e-03 -6.27e-06 -2.22e-06 -6.92e-05]"
   ],
   "id": "d33f676af67fb7ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5.2 多变量梯度下降\n",
    "\n",
    "下面的例程实现了上面的等式（5）。"
   ],
   "id": "1703731cd9f2f1c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:44.510162Z",
     "start_time": "2024-05-12T14:42:44.496155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gradient_descent(x, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters):\n",
    "    j_history = []\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    for i in range(num_iters):\n",
    "        dj_db, dj_dw = gradient_function(x, y, w, b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "        j_history.append(cost_function(x, y, w, b))\n",
    "        if i % math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {j_history[-1]:8.2f}   \")\n",
    "    return w, b, j_history"
   ],
   "id": "43aacf3d971fb8ef",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在下一个单元中，您将测试实现。",
   "id": "d16b958d56f7beeb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:54.952625Z",
     "start_time": "2024-05-12T14:42:44.511163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "initial_w = np.zeros_like(w_init)\n",
    "initial_b = 0.\n",
    "iterations = 1000000\n",
    "alpha = 5.0e-7\n",
    "w_final, b_final, J_hist = gradient_descent(X_train, y_train, initial_w, initial_b, compute_cost, compute_gradient,\n",
    "                                            alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m, _ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ],
   "id": "e80a8ea83bf5510e",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T14:42:55.278299Z",
     "start_time": "2024-05-12T14:42:54.954626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, constrained_layout=True, figsize=(12, 4))\n",
    "ax1.plot(J_hist)\n",
    "ax2.plot(500000 + np.arange(len(J_hist[500000:])), J_hist[500000:])\n",
    "ax1.set_title(\"Cost vs. iteration\")\n",
    "ax2.set_title(\"Cost vs. iteration (tail)\")\n",
    "ax1.set_ylabel('Cost')\n",
    "ax2.set_ylabel('Cost')\n",
    "ax1.set_xlabel('iteration step')\n",
    "ax2.set_xlabel('iteration step')\n",
    "plt.show()"
   ],
   "id": "1d1368efd3d095d7",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "*这些结果并不鼓舞人心*！成本仍在下降，我们的预测也不是很准确。下一个实验室将探讨如何改进这一点。",
   "id": "ccf7731cee0fc352"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 6 恭喜！\n",
    "\n",
    "在本实验室中，您：\n",
    "\n",
    "- 重新开发了线性回归例程，现在具有多个变量。\n",
    "- 利用NumPy`np.dot`对实现进行矢量化"
   ],
   "id": "9522a30e506ae400"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
