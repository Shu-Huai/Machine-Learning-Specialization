{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 可选实验室——神经元和层\n",
    "\n",
    "在这个实验室中，我们将探索神经元/单元和层的内部运作。特别是，实验室将与您在课程1中掌握的模型、回归/线性模型和逻辑模型进行比较。该实验室将介绍Tensorflow并演示如何在该框架中实现这些模型。\n",
    "\n",
    "<figure>\n",
    "   <img src=\"../../images/C2_W1_NeuronsAndLayers.png\" style=\"width:540px;height:200px;\" >\n",
    "</figure>"
   ],
   "id": "8b42dd38d81e164b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 套餐\n",
    "\n",
    "**TensorFlow和Keras**\n",
    "\n",
    "Tensorflow是Google开发的机器学习包。2019年，谷歌将Keras集成到Tensorflow中，并发布了Tensorflow 2.0。Keras是François Chollet独立开发的框架，它创建了一个简单的、以层为中心的Tensorflow接口。本课程将使用Keras界面。"
   ],
   "id": "c35334ac1e5ce71c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:04.172636Z",
     "start_time": "2024-05-17T08:50:50.917510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from lab_utils_common import dlc\n",
    "from lab_neurons_utils import sigmoidnp, plt_linear, plt_logistic\n",
    "\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config, )"
   ],
   "id": "cfc771019420bc4f",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 未激活的神经元——回归/线性模型",
   "id": "596ce0fc95ee901"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 数据集\n",
    "\n",
    "我们将使用课程1中房价线性回归的示例。"
   ],
   "id": "2fd15fe42be28417"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:04.311299Z",
     "start_time": "2024-05-17T08:51:04.173915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(X_train, Y_train, marker='x', c='r', label=\"Data Points\")\n",
    "ax.legend(fontsize='xx-large')\n",
    "ax.set_ylabel('Price (in 1000s of dollars)', fontsize='xx-large')\n",
    "ax.set_xlabel('Size (1000 sqft)', fontsize='xx-large')\n",
    "plt.show()"
   ],
   "id": "9a735f9e3fb558d2",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 回归/线性模型\n",
    "\n",
    "没有激活的神经元实现的函数与课程1线性回归中的相同：\n",
    "\n",
    "$$f_{\\mathbf{w},b}(x^{(i)})=\\mathbf{w}\\cdot x^{(i)}+b\\tag{1}$$"
   ],
   "id": "b8a3b34e36cff081"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们可以用一个神经元或单元定义一层，并将其与熟悉的线性回归函数进行比较。",
   "id": "f083f5d76915a702"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:04.326808Z",
     "start_time": "2024-05-17T08:51:04.312299Z"
    }
   },
   "cell_type": "code",
   "source": "linear_layer = tf.keras.layers.Dense(units=1, activation='linear', )",
   "id": "7837186f0997703b",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "让我们检查一下权重。",
   "id": "c033df1f13b9c906"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:04.342424Z",
     "start_time": "2024-05-17T08:51:04.328408Z"
    }
   },
   "cell_type": "code",
   "source": "linear_layer.get_weights()",
   "id": "ef9e842a768c77e6",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "没有权重，因为权重尚未实例化。让我们在`X_train`中的一个示例中尝试该模型。这将触发权重的实例化。请注意，该层的输入必须是二维的，因此我们将对其进行重塑。",
   "id": "158c3e4c0f753fa2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.394556Z",
     "start_time": "2024-05-17T08:51:04.343924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1, 1))\n",
    "print(a1)"
   ],
   "id": "e0d06436426f1c4a",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "结果是一个形状为(1,1)或一个条目的张量（数组的另一个名称）。\n",
    "\n",
    "现在让我们看看权重和偏差。这些权重随机初始化为小数，偏差默认初始化为零。"
   ],
   "id": "d6f6fc3fc513d028"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.409636Z",
     "start_time": "2024-05-17T08:51:06.395558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "w, b = linear_layer.get_weights()\n",
    "print(f\"w = {w}, b={b}\")"
   ],
   "id": "5303cc28a04d6571",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "具有单个输入特征的线性回归模型（1）将具有单个权重和偏差。这与上面`linear_layer`的尺寸相匹配。\n",
    "\n",
    "权重被初始化为随机值，因此我们将它们设置为一些已知值。"
   ],
   "id": "5f1f2c6661aa1a75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.425645Z",
     "start_time": "2024-05-17T08:51:06.411137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "linear_layer.set_weights([set_w, set_b])\n",
    "print(linear_layer.get_weights())"
   ],
   "id": "3caa1890bcd05648",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "让我们将方程（1）与层输出进行比较。",
   "id": "a6ae78376fdedfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.440621Z",
     "start_time": "2024-05-17T08:51:06.426645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1, 1))\n",
    "print(a1)\n",
    "alin = np.dot(set_w, X_train[0].reshape(1, 1)) + set_b\n",
    "print(alin)"
   ],
   "id": "65c602d48037dcf5",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "他们产生相同的价值观！\n",
    "\n",
    "现在，我们可以使用线性层对训练数据进行预测。"
   ],
   "id": "f2f950b14c3c7554"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.456131Z",
     "start_time": "2024-05-17T08:51:06.441621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction_tf = linear_layer(X_train)\n",
    "prediction_np = np.dot(X_train, set_w) + set_b"
   ],
   "id": "99aad42940c9ad1e",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.750296Z",
     "start_time": "2024-05-17T08:51:06.457735Z"
    }
   },
   "cell_type": "code",
   "source": "plt_linear(X_train, Y_train, prediction_tf, prediction_np)",
   "id": "e208a7d8c94f53b0",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 具有Sigmoid激活的神经元\n",
    "\n",
    "具有sigmoid激活的神经元/单元实现的函数与课程1逻辑回归中的相同：\n",
    "\n",
    "$$f_{\\mathbf{w},b}(x^{(i)})=g(\\mathbf{w}x^{(i)}+b)\\tag{2}$$\n",
    "\n",
    "其中$$g(x)=sigmoid(x)$$\n",
    "\n",
    "让我们将$w$和$b$设置为一些已知值并检查模型。"
   ],
   "id": "9fcc97a9c1f5337b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 数据集\n",
    "\n",
    "我们将使用课程1逻辑回归中的示例。"
   ],
   "id": "926d2d0636611a2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.766366Z",
     "start_time": "2024-05-17T08:51:06.760367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1, 1)\n",
    "Y_train = np.array([0, 0, 0, 1, 1, 1], dtype=np.float32).reshape(-1, 1)"
   ],
   "id": "ee5fedfbcb128900",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.782174Z",
     "start_time": "2024-05-17T08:51:06.767366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "X_train[pos]"
   ],
   "id": "479d27756d0c9a4a",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.858388Z",
     "start_time": "2024-05-17T08:51:06.783178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "ax.scatter(X_train[pos], Y_train[pos], marker='x', s=80, c='red', label=\"y=1\")\n",
    "ax.scatter(X_train[neg], Y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', edgecolors=dlc[\"dlblue\"],\n",
    "           lw=3)\n",
    "ax.set_ylim(-0.08, 1.1)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_title('one variable plot')\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ],
   "id": "c98e4e2515d16513",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 逻辑神经元\n",
    "\n",
    "我们可以通过添加sigmoid激活来实现“逻辑神经元”。神经元的功能由上面的（2）描述。\n",
    "\n",
    "本节将创建一个包含逻辑层的Tensorflow模型，以演示创建模型的替代方法。Tensorflow最常用于创建多层模型。[Sequential](https://keras.io/guides/sequential_model/)模型是构建这些模型的便捷方法。"
   ],
   "id": "eb6622df203a5a97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.889026Z",
     "start_time": "2024-05-17T08:51:06.859887Z"
    }
   },
   "cell_type": "code",
   "source": "model = Sequential([tf.keras.layers.Dense(1, input_dim=1, activation='sigmoid', name='L1')])",
   "id": "71a5c18adb03ce97",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "model.summary()显示模型中的层数和参数数量。该模型中只有一层，并且该层只有一个单元。该单位有两个参数：$w$和$b$。",
   "id": "4a34100e16870bf4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.904616Z",
     "start_time": "2024-05-17T08:51:06.890526Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "4390e14f707e3b81",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.920626Z",
     "start_time": "2024-05-17T08:51:06.906119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logistic_layer = model.get_layer('L1')\n",
    "w, b = logistic_layer.get_weights()\n",
    "print(w, b)\n",
    "print(w.shape, b.shape)"
   ],
   "id": "f251ac715d0bb4a3",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "让我们将权重和偏差设置为一些已知值。",
   "id": "3fc5edbc54f669ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:06.936129Z",
     "start_time": "2024-05-17T08:51:06.922126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "logistic_layer.set_weights([set_w, set_b])\n",
    "print(logistic_layer.get_weights())"
   ],
   "id": "35a017f3033a5b76",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "让我们将方程（2）与层输出进行比较。",
   "id": "103ff337e37bbba7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:07.167328Z",
     "start_time": "2024-05-17T08:51:06.937129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a1 = model.predict(X_train[0].reshape(1, 1))\n",
    "print(a1)\n",
    "alog = sigmoidnp(np.dot(set_w, X_train[0].reshape(1, 1)) + set_b)\n",
    "print(alog)"
   ],
   "id": "3a0e50726c379d2a",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "他们产生相同的价值观！\n",
    "\n",
    "现在，我们可以使用逻辑层和NumPy模型对训练数据进行预测。"
   ],
   "id": "a1fb2d2f33d7ce3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T08:51:09.486515Z",
     "start_time": "2024-05-17T08:51:07.169252Z"
    }
   },
   "cell_type": "code",
   "source": "plt_logistic(X_train, Y_train, model, set_w, set_b, pos, neg)",
   "id": "f37f18ae85f79d51",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "上面的阴影反映了sigmoid的输出，其范围从0到1。",
   "id": "133fca40912b2be8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 恭喜！\n",
    "\n",
    "您构建了一个非常简单的神经网络，并探索了神经元与课程1中的线性回归和逻辑回归的相似之处。"
   ],
   "id": "2d432fd4b515e14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
