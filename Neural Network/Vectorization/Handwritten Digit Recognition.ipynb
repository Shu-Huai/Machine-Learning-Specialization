{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 用于手写数字识别的神经网络，二进制\n",
    "\n",
    "在本练习中，您将使用神经网络来识别手写数字0和1。\n",
    "\n",
    "# 大纲\n",
    "\n",
    "- [1 包]()\n",
    "- [2 神经网络]()\n",
    "   - [2.1 问题陈述]()\n",
    "   - [2.2 数据集]()\n",
    "   - [2.3 模型表示]()\n",
    "   - [2.4 Tensorflow 模型实现]()\n",
    "     - [练习1]()\n",
    "   - [2.5 NumPy模型实现（NumPy中的Forward Prop）]()\n",
    "     - [练习2]()\n",
    "   - [2.6 矢量化NumPy模型实现（可选）]()\n",
    "     - [练习3]()\n",
    "   - [2.7 恭喜！]()\n",
    "   - [2.8 NumPy广播教程（可选）]()"
   ],
   "id": "b56077d3ffe4c441"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1 套餐\n",
    "\n",
    "首先，让我们运行下面的单元来导入您在此作业期间需要的所有包。\n",
    "\n",
    "- [numpy](https://numpy.org/)是使用Python进行科学计算的基础包。\n",
    "- [matplotlib](https://matplotlib.org)是一个流行的Python绘图库。\n",
    "- [tensorflow](https://www.tensorflow.org/)一个流行的机器学习平台。"
   ],
   "id": "8e8f1503d2811b18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:50.260871Z",
     "start_time": "2024-05-18T08:08:36.734684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from autils import *\n",
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config, )"
   ],
   "id": "75927cf735914ab0",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**TensorFlow和Keras**\n",
    "\n",
    "Tensorflow是Google开发的机器学习包。2019年，谷歌将Keras集成到Tensorflow中，并发布了Tensorflow 2.0。Keras是François Chollet独立开发的框架，它创建了一个简单的、以层为中心的Tensorflow接口。本课程将使用Keras界面。"
   ],
   "id": "f1d30d8d4358c798"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2 神经网络\n",
    "\n",
    "在课程1中，您实现了逻辑回归。这被扩展为使用多项式回归处理非线性边界。对于图像识别等更复杂的场景，神经网络是首选。\n",
    "\n",
    "### 2.1 问题陈述\n",
    "\n",
    "在本练习中，您将使用神经网络来识别两个手写数字：零和一。这是一个二元分类任务。自动手写数字识别如今已得到广泛应用——从识别邮件信封上的邮政编码（邮政编码）到识别银行支票上的金额。您将扩展此网络，以便在将来的作业中识别所有10个数字（0-9）。\n",
    "\n",
    "本练习将向您展示如何将您学到的方法用于此分类任务。\n",
    "\n",
    "### 2.2 数据集\n",
    "\n",
    "您将首先加载此任务的数据集。\n",
    "\n",
    "- 下面显示的`load_data()`函数将数据加载到变量`X`和`y`中\n",
    "- 数据集包含1000个手写数字$^1$的训练示例，这里限制为0和1。\n",
    "    - 每个训练示例都是数字的20像素x20像素灰度图像。\n",
    "        - 每个像素都由浮点数表示，指示该位置的灰度强度。\n",
    "        - 20x20像素网格“展开”为400维向量。\n",
    "        - 每个训练示例都成为数据矩阵`X`中的一行。\n",
    "        - 这为我们提供了一个1000x400矩阵`X`，其中每一行都是手写数字图像的训练示例。\n",
    "\n",
    "$$X = \n",
    "\\left(\\begin{array}{cc} \n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\ \n",
    "--- (x^{(m)}) --- \n",
    "\\end{array}\\right)$$ \n",
    "\n",
    "- 训练集的第二部分是一个1000x1维向量`y`，其中包含训练集的标签\n",
    "    - 如果图像是数字`0`，则`y = 0`；如果图像是数字`1`，则`y = 1`。\n",
    "\n",
    "$^1$<sub>这是MNIST手写数字数据集的子集 (https://yann.lecun.com/exdb/mnist/)</sub>"
   ],
   "id": "75c85b9b5c91094b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:50.600816Z",
     "start_time": "2024-05-18T08:08:50.262081Z"
    }
   },
   "cell_type": "code",
   "source": "X, y = load_data()",
   "id": "24a529d552c3fa43",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2.1 查看变量\n",
    "\n",
    "让我们更熟悉您的数据集。\n",
    "\n",
    "- 一个好的起点是打印出每个变量并查看它包含的内容。\n",
    "\n",
    "下面的代码打印变量`X`和`y`的元素。"
   ],
   "id": "40fb508866eb27c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:50.615916Z",
     "start_time": "2024-05-18T08:08:50.601819Z"
    }
   },
   "cell_type": "code",
   "source": "print('The first element of X is: ', X[0])",
   "id": "a367fd1c537158a3",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:50.631151Z",
     "start_time": "2024-05-18T08:08:50.616919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('The first element of y is: ', y[0, 0])\n",
    "print('The last element of y is: ', y[-1, 0])"
   ],
   "id": "e8a4be30f615d5cd",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2.2 检查变量的维度\n",
    "\n",
    "熟悉数据的另一种方法是查看其维度。请打印`X`和`y`的形状，并查看数据集中有多少个训练示例。"
   ],
   "id": "98a169f64cc41f01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:50.646771Z",
     "start_time": "2024-05-18T08:08:50.632654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('The shape of X is: ' + str(X.shape))\n",
    "print('The shape of y is: ' + str(y.shape))"
   ],
   "id": "a5583c3a59d520d4",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2.3 可视化数据\n",
    "\n",
    "您将首先可视化训练集的子集。\n",
    "\n",
    "- 在下面的单元格中，代码从`X`中随机选择64行，将每行映射回20像素x20像素的灰度图像，并将图像一起显示。\n",
    "- 每个图像的标签显示在图像上方"
   ],
   "id": "24679cb18f34bd67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:51.996273Z",
     "start_time": "2024-05-18T08:08:50.647774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "m, n = X.shape\n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "fig.tight_layout(pad=0.1)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    random_index = np.random.randint(m)\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    ax.set_title(y[random_index, 0])\n",
    "    ax.set_axis_off()"
   ],
   "id": "1a7539c7849eb9f",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3 模型表示\n",
    "\n",
    "您将在本次作业中使用的神经网络如下图所示。\n",
    "\n",
    "- 它具有三个带有sigmoid激活的密集层。\n",
    "    - 回想一下，我们的输入是数字图像的像素值。\n",
    "    - 由于图像大小为$20\\times20$，这为我们提供了$400$输入\n",
    "    \n",
    "<img src=\"../../images/C2_W1_Assign1.PNG\" width=\"500\" height=\"400\">"
   ],
   "id": "2b28701859b36816"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 参数的尺寸适合神经网络，第1层为$25$单位，第2层为$15$单位，第3层为$1$输出单位。\n",
    "    - 回想一下，这些参数的维度确定如下：\n",
    "        - 如果网络在一层中有$s_{in}$单元，在下一层有$s_{out}$单元，则\n",
    "            - $W$的尺寸为$s_{in}\\times s_{out}$。\n",
    "            - $b$将是一个带有$s_{out}$元素的向量\n",
    "    - 因此，`W`和`b`的形状是\n",
    "        - 第1层：`W1`的形状为`(400, 25)`，`b1`的形状为`(25,)`\n",
    "        - 第2层：`W2`的形状是`(25, 15)`，`b2`的形状是：`(15,)`\n",
    "        - 第3层：`W3`的形状是`(15, 1)`，`b3`的形状是：`(1,)`\n",
    "\n",
    ">**注意：** 偏差向量b可以表示为一维`(n,)`或二维`(n,1)`数组。Tensorflow使用一维表示，本实验室将维持该约定。"
   ],
   "id": "b2fc83bc5d427d32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.4 Tensorflow模型实现",
   "id": "28c6dc0c6aeca418"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Tensorflow模型是逐层构建的。图层的输入尺寸（上面的$s_{in}$）是为您计算的。您指定图层的*输出尺寸*，这决定了下一层的输入尺寸。第一层的输入维度源自下面`model.fit`语句中指定的输入数据的大小。\n",
    "\n",
    ">**注意：** 还可以添加一个输入层，指定第一层的输入维度。例如：`tf.keras.Input(shape=(400,)), #指定输入形状`我们将在这里添加它来说明一些模型尺寸。"
   ],
   "id": "cc2e358c494c79bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 练习1\n",
    "\n",
    "下面，使用Keras[顺序模型](https://keras.io/guides/sequential_model/)和[密集层](https://keras.io/api/layers/core_layers/dense/)以及sigmoid激活构建上述网络。"
   ],
   "id": "fd56d5ee81e28db5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:52.104565Z",
     "start_time": "2024-05-18T08:08:51.997276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential(\n",
    "    [tf.keras.Input(shape=(400,)), Dense(units=25, activation='sigmoid'), Dense(units=15, activation='sigmoid'),\n",
    "     Dense(units=1, activation='sigmoid')], name=\"my_model\")"
   ],
   "id": "4d38548cf29262f9",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:52.120196Z",
     "start_time": "2024-05-18T08:08:52.105566Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "c519ed5ba90f7634",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:52.150855Z",
     "start_time": "2024-05-18T08:08:52.121070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from public_tests import *\n",
    "\n",
    "test_c1(model)"
   ],
   "id": "1e9b49ce6b51b4e9",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "摘要中显示的参数计数对应于权重和偏差数组中的元素数量，如下所示。",
   "id": "2f4aa9e7932c97f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:52.166369Z",
     "start_time": "2024-05-18T08:08:52.151855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "L1_num_params = 400 * 25 + 25\n",
    "L2_num_params = 25 * 15 + 15\n",
    "L3_num_params = 15 * 1 + 1\n",
    "print(\"L1 params = \", L1_num_params, \", L2 params = \", L2_num_params, \",  L3 params = \", L3_num_params)"
   ],
   "id": "cebeda5974b32176",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "让我们进一步检查权重，以验证张量流产生的尺寸与我们上面计算的尺寸相同。",
   "id": "eb6fecd8682cfbae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:52.181926Z",
     "start_time": "2024-05-18T08:08:52.167371Z"
    }
   },
   "cell_type": "code",
   "source": "[layer1, layer2, layer3] = model.layers",
   "id": "1fc10f504cecfc2",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:52.197446Z",
     "start_time": "2024-05-18T08:08:52.182929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W1, b1 = layer1.get_weights()\n",
    "W2, b2 = layer2.get_weights()\n",
    "W3, b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ],
   "id": "e94bcbc1b4f78f50",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**期望输出**\n",
    "\n",
    "```\n",
    "W1 shape = (400, 25), b1 shape = (25,)  \n",
    "W2 shape = (25, 15), b2 shape = (15,)  \n",
    "W3 shape = (15, 1), b3 shape = (1,)\n",
    "```"
   ],
   "id": "452a7ab8b9e72d3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`xx.get_weights`返回一个NumPy数组。人们还可以直接以张量形式访问权重。注意最后一层张量的形状。",
   "id": "a93983e22518f59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:52.212674Z",
     "start_time": "2024-05-18T08:08:52.198445Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.layers[2].weights)",
   "id": "12655f919e60a04",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "以下代码将定义损失函数并运行梯度下降以使模型的权重适合训练数据。这将在下周进行更详细的解释。",
   "id": "8dc3a8bc6672ab78"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:56.082358Z",
     "start_time": "2024-05-18T08:08:52.214175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "model.fit(X, y, epochs=20)"
   ],
   "id": "d9458017456d061c",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "要在示例上运行模型以进行预测，请使用[Keras `predict`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)。`predict`的输入是一个数组，因此单个示例被重塑为二维。",
   "id": "81b7562aabff7540"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:56.206272Z",
     "start_time": "2024-05-18T08:08:56.083361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = model.predict(X[0].reshape(1, 400))\n",
    "print(f\" predicting a zero: {prediction}\")\n",
    "prediction = model.predict(X[500].reshape(1, 400))\n",
    "print(f\" predicting a one:  {prediction}\")"
   ],
   "id": "1efe6fe0d5a6c4c2",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:08:56.221284Z",
     "start_time": "2024-05-18T08:08:56.207274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print(f\"prediction after threshold: {yhat}\")"
   ],
   "id": "798048f9b23250e1",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "让我们比较64位随机样本的预测与标签。这需要一些时间来运行。",
   "id": "f8304463ecbcc152"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:00.341065Z",
     "start_time": "2024-05-18T08:08:56.222284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "m, n = X.shape\n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "fig.tight_layout(pad=0.1, rect=[0, 0.03, 1, 0.92])\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    random_index = np.random.randint(m)\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    prediction = model.predict(X[random_index].reshape(1, 400))\n",
    "    if prediction >= 0.5:\n",
    "        yhat = 1\n",
    "    else:\n",
    "        yhat = 0\n",
    "    ax.set_title(f\"{y[random_index, 0]},{yhat}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, yhat\", fontsize=16)\n",
    "plt.show()"
   ],
   "id": "94f1088783162304",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.5 NumPy模型实现（NumPy中的Forward Prop）\n",
    "\n",
    "正如讲座中所述，可以使用NumPy构建自己的密集层。然后可以利用它来构建多层神经网络。\n",
    "\n",
    "<img src=\"../../images/C2_W1_dense2.PNG\" width=\"600\" height=\"450\">"
   ],
   "id": "d12211ba12198c87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 练习2\n",
    "\n",
    "下面，构建一个致密层子程序。讲座中的示例使用for循环来访问层中的每个单元（`j`）并执行该单元权重的点积（`W[:,j]`）并对单元的偏差求和（` b[j]`）形成`z`。然后将激活函数`g(z)`应用于该结果。本节将不会使用可选讲座中描述的一些矩阵运算。这些将在后面的部分中探讨。"
   ],
   "id": "51758b41edf4df1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:00.356578Z",
     "start_time": "2024-05-18T08:09:00.342066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_dense(a_in, W, b, g):\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for i in range(units):\n",
    "        a_out[i] = np.dot(a_in, W[:, i]) + b[i]\n",
    "        a_out[i] = g(a_out[i])\n",
    "    return a_out"
   ],
   "id": "5e025a9c4dc5ffb3",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:00.372084Z",
     "start_time": "2024-05-18T08:09:00.357579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_tst = 0.1 * np.arange(1, 3, 1).reshape(2, )\n",
    "W_tst = 0.1 * np.arange(1, 7, 1).reshape(2, 3)\n",
    "b_tst = 0.1 * np.arange(1, 4, 1).reshape(3, )\n",
    "A_tst = my_dense(x_tst, W_tst, b_tst, sigmoid)\n",
    "print(A_tst)"
   ],
   "id": "b0ac72bec427b99d",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**期望输出**\n",
    "\n",
    "```\n",
    "[0.54735762 0.57932425 0.61063923]\n",
    "```"
   ],
   "id": "3e15af431e875212"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:00.387395Z",
     "start_time": "2024-05-18T08:09:00.373385Z"
    }
   },
   "cell_type": "code",
   "source": "test_c2(my_dense)",
   "id": "b33200fc4e1b7695",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "以下单元利用上面的`my_dense`子例程构建一个三层神经网络。",
   "id": "48dbf8914f32f10d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:00.402900Z",
     "start_time": "2024-05-18T08:09:00.388395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_sequential(x, W1, b1, W2, b2, W3, b3):\n",
    "    a1 = my_dense(x, W1, b1, sigmoid)\n",
    "    a2 = my_dense(a1, W2, b2, sigmoid)\n",
    "    a3 = my_dense(a2, W3, b3, sigmoid)\n",
    "    return a3"
   ],
   "id": "dc176f51f05b0fed",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们可以从Tensorflow复制经过训练的权重和偏差。",
   "id": "7f84d0193188b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:00.418409Z",
     "start_time": "2024-05-18T08:09:00.403900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W1_tmp, b1_tmp = layer1.get_weights()\n",
    "W2_tmp, b2_tmp = layer2.get_weights()\n",
    "W3_tmp, b3_tmp = layer3.get_weights()"
   ],
   "id": "50301d73815510a3",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:00.449421Z",
     "start_time": "2024-05-18T08:09:00.419916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = my_sequential(X[0], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp)\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print(\"yhat = \", yhat, \" label= \", y[0, 0])\n",
    "prediction = my_sequential(X[500], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp)\n",
    "if prediction >= 0.5:\n",
    "    yhat = 1\n",
    "else:\n",
    "    yhat = 0\n",
    "print(\"yhat = \", yhat, \" label= \", y[500, 0])"
   ],
   "id": "e761ea99da0701b4",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "运行以下单元格以查看Numpy模型和Tensorflow模型的预测。这需要一些时间来运行。",
   "id": "cac6e4b030f379b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:05.238118Z",
     "start_time": "2024-05-18T08:09:00.450421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "m, n = X.shape\n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "fig.tight_layout(pad=0.1, rect=[0, 0.03, 1, 0.92])\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    random_index = np.random.randint(m)\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    my_prediction = my_sequential(X[random_index], W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp)\n",
    "    my_yhat = int(my_prediction[0] >= 0.5)\n",
    "    tf_prediction = model.predict(X[random_index].reshape(1, 400))\n",
    "    tf_yhat = int(tf_prediction[0][0] >= 0.5)\n",
    "    ax.set_title(f\"{y[random_index, 0]},{tf_yhat},{my_yhat}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, yhat Tensorflow, yhat Numpy\", fontsize=16)\n",
    "plt.show()"
   ],
   "id": "4d477d3c6ee7af8a",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.6 向量化NumPy模型实现（可选）\n",
    "\n",
    "可选讲座描述了可用于加速计算的向量和矩阵运算。\n",
    "\n",
    "下面描述了一个层操作，该操作在给定的输入示例上计算层中所有单元的输出：\n",
    "\n",
    "<img src=\"../../images/C2_W1_VectorMatrix.PNG\" width=\"600\" height=\"450\">\n",
    "\n",
    "我们可以使用上面的示例`X`和`W1`、`b1`参数来演示这一点。我们使用`np.matmul`来执行矩阵乘法。请注意，`x`和`W`的尺寸必须兼容，如上图所示。"
   ],
   "id": "b85d6a170a04a752"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:05.253632Z",
     "start_time": "2024-05-18T08:09:05.239120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = X[0].reshape(-1, 1)\n",
    "z1 = np.matmul(x.T, W1) + b1\n",
    "a1 = sigmoid(z1)\n",
    "print(a1.shape)"
   ],
   "id": "56b8b207eff3be9c",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "您可以更进一步，在一次矩阵-矩阵运算中计算所有示例的所有单位。\n",
    "\n",
    "<img src=\"../../images/C2_W1_MatrixMatrix.PNG\" width=\"600\" height=\"450\">\n",
    "\n",
    "完整的运算是$\\mathbf{Z}=\\mathbf{XW}+\\mathbf{b}$。这将利用NumPy广播将$\\mathbf{b}$扩展到$m$行。如果这不熟悉，笔记本末尾提供了一个简短的教程。"
   ],
   "id": "80a7dabc01bab616"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 练习3\n",
    "\n",
    "下面，编写一个新的`my_dense_v`子例程，该子例程对示例矩阵执行层计算。这将利用`np.matmul()`。"
   ],
   "id": "488ddb1e84d9c5c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:05.269132Z",
     "start_time": "2024-05-18T08:09:05.254633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_dense_v(A_in, W, b, g):\n",
    "    A_out = np.matmul(A_in, W) + b\n",
    "    A_out = g(A_out)\n",
    "    return A_out"
   ],
   "id": "c25e1356742ff20b",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:05.284757Z",
     "start_time": "2024-05-18T08:09:05.270251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_tst = 0.1 * np.arange(1, 9, 1).reshape(4, 2)\n",
    "W_tst = 0.1 * np.arange(1, 7, 1).reshape(2, 3)\n",
    "b_tst = 0.1 * np.arange(1, 4, 1).reshape(1, 3)\n",
    "A_tst = my_dense_v(X_tst, W_tst, b_tst, sigmoid)\n",
    "print(A_tst)"
   ],
   "id": "7e1614dca3116d30",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**期望输出**\n",
    "\n",
    "```\n",
    "[[0.54735762 0.57932425 0.61063923]\n",
    " [0.57199613 0.61301418 0.65248946]\n",
    " [0.5962827  0.64565631 0.6921095 ]\n",
    " [0.62010643 0.67699586 0.72908792]]\n",
    " ```"
   ],
   "id": "edee729eb0d1da68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:05.300334Z",
     "start_time": "2024-05-18T08:09:05.285757Z"
    }
   },
   "cell_type": "code",
   "source": "test_c3(my_dense_v)",
   "id": "2d111518fe7106c0",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "以下单元利用上面的`my_dense_v`子例程构建一个三层神经网络。",
   "id": "42bd30964fb0df97"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:09:41.768183Z",
     "start_time": "2024-05-18T08:09:41.761184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_sequential_v(X, W1, b1, W2, b2, W3, b3):\n",
    "    A1 = my_dense_v(X, W1, b1, sigmoid)\n",
    "    A2 = my_dense_v(A1, W2, b2, sigmoid)\n",
    "    A3 = my_dense_v(A2, W3, b3, sigmoid)\n",
    "    return A3"
   ],
   "id": "e1120ee7df427853",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们可以再次从Tensorflow复制经过训练的权重和偏差。",
   "id": "a10975bd130e6966"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:10:09.001535Z",
     "start_time": "2024-05-18T08:10:08.983425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "W1_tmp, b1_tmp = layer1.get_weights()\n",
    "W2_tmp, b2_tmp = layer2.get_weights()\n",
    "W3_tmp, b3_tmp = layer3.get_weights()"
   ],
   "id": "612afd090d5c385d",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "让我们用新模型进行预测。这将同时对*所有示例*进行预测。注意输出的形状。",
   "id": "c712fcb8c9a99db1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:10:28.991961Z",
     "start_time": "2024-05-18T08:10:28.965885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Prediction = my_sequential_v(X, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp)\n",
    "Prediction.shape"
   ],
   "id": "4f28f12298b275bf",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "我们将像以前一样应用0.5的阈值，但同时应用于所有预测。",
   "id": "45a6ef6f4093321b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:11:23.420971Z",
     "start_time": "2024-05-18T08:11:23.388814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Yhat = (Prediction >= 0.5).numpy().astype(int)\n",
    "print(\"predict a zero: \", Yhat[0], \"predict a one: \", Yhat[500])"
   ],
   "id": "2811e5ab4297b2cd",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "运行以下单元格以查看预测。这将使用我们上面刚刚计算的预测。这需要一些时间来运行。",
   "id": "d99e8116619d3243"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:12:07.655059Z",
     "start_time": "2024-05-18T08:12:06.218365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "m, n = X.shape\n",
    "fig, axes = plt.subplots(8, 8, figsize=(8, 8))\n",
    "fig.tight_layout(pad=0.1, rect=[0, 0.03, 1, 0.92])\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    random_index = np.random.randint(m)\n",
    "    X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "    ax.imshow(X_random_reshaped, cmap='gray')\n",
    "    ax.set_title(f\"{y[random_index, 0]}, {Yhat[random_index, 0]}\")\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, Yhat\", fontsize=16)\n",
    "plt.show()"
   ],
   "id": "a6b385a62d72d2f6",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "您可以看到其中一张错误分类的图像的外观。",
   "id": "273d42dbad1e8458"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:13:06.415716Z",
     "start_time": "2024-05-18T08:13:06.371690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig = plt.figure(figsize=(1, 1))\n",
    "errors = np.where(y != Yhat)\n",
    "random_index = errors[0][0]\n",
    "X_random_reshaped = X[random_index].reshape((20, 20)).T\n",
    "plt.imshow(X_random_reshaped, cmap='gray')\n",
    "plt.title(f\"{y[random_index, 0]}, {Yhat[random_index, 0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "2c804b604cb9cb85",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.7 恭喜！\n",
    "\n",
    "您已经成功构建并使用了神经网络。"
   ],
   "id": "361e8f5c49a79027"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.8 NumPy广播教程（可选）",
   "id": "ad250a3229d5485"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在最后一个例子中，$\\mathbf{Z}=\\mathbf{XW}+\\mathbf{b}$利用NumPy广播来扩展向量$\\mathbf{b}$。如果您不熟悉NumPy广播，可以阅读此简短教程。\n",
    "\n",
    "$\\mathbf{XW}$是维度为$(m,j_1)(j_1,j_2)$的矩阵-矩阵运算，生成维度为$(m,j_2)$的矩阵。为此，我们添加一个维度为$(j_2,)$的向量$\\mathbf{b}$。$\\mathbf{b}$必须扩展为$(m,j_2)$矩阵，此逐元素运算才有意义。此扩展是通过NumPy广播为您完成的。"
   ],
   "id": "a8ff70473cd7ab5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "广播适用于逐元素操作。\n",
    "\n",
    "其基本操作是通过复制元素来“拉伸”较小的维度以匹配较大的维度。\n",
    "\n",
    "更多[具体](https://NumPy.org/doc/stable/user/basics.broadcasting.html)：\n",
    "\n",
    "当操作两个数组时，NumPy按元素比较它们的形状。它从尾随（即最右边）尺寸开始并向左移动。两个维度兼容时\n",
    "\n",
    "- 它们是相等的，或者\n",
    "- 其中之一是1\n",
    "\n",
    "如果不满足这些条件，则会抛出ValueError: operands Could not be Broadcast Together异常，表明数组的形状不兼容。结果数组的大小是沿输入的每个轴不为1的大小。\n",
    "\n",
    "这里有些例子："
   ],
   "id": "1abcea2100c9533b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<figure>\n",
    "    <center>\n",
    "        <img src=\"../../images/C2_W1_Assign1_BroadcastIndexes.png\" alt='missing' width=\"400\">\n",
    "    <center/>\n",
    "    <figcaption>\n",
    "        计算广播结果形状\n",
    "    </figcaption>\n",
    "<figure/>"
   ],
   "id": "93cecb03e6c50e22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "下图描述了扩展尺寸。注意下面红色文字：",
   "id": "1077db5a9d3261f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<figure>\n",
    "    <center>\n",
    "        <img src=\"../../images/C2_W1_Assign1_Broadcasting.gif\" alt='missing' width=\"600\">\n",
    "    <center/>\n",
    "    <figcaption>\n",
    "        广播理论上扩展了参数以匹配元素明智的操作\n",
    "    </figcaption>\n",
    "<figure/>"
   ],
   "id": "1ef8654718e7f2d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "上图显示NumPy在最终操作之前扩展参数以进行匹配。请注意，这是一个概念性的描述。NumPy操作的实际机制选择最有效的实现。\n",
    "\n",
    "对于以下每个示例，请在运行示例之前尝试猜测结果的大小。"
   ],
   "id": "cdb77119653b49b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:18:07.616552Z",
     "start_time": "2024-05-18T08:18:07.610546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.array([1, 2, 3]).reshape(-1, 1)\n",
    "b = 5\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ],
   "id": "147b6b83d946ca31",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "请注意，这适用于所有逐元素操作：",
   "id": "8c686d36887949a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:18:30.133267Z",
     "start_time": "2024-05-18T08:18:30.119685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.array([1, 2, 3]).reshape(-1, 1)\n",
    "b = 5\n",
    "print(f\"(a * b).shape: {(a * b).shape}, \\na * b = \\n{a * b}\")"
   ],
   "id": "10f49c41d4ff4210",
   "execution_count": 37,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<figure>\n",
    "    <img src=\"../../images/C2_W1_Assign1_VectorAdd.PNG\" alt='missing' width=\"740\" >\n",
    "    <center>\n",
    "        <figcaption>\n",
    "            <b>\n",
    "                行列逐元素运算\n",
    "            </b>\n",
    "        </figcaption>\n",
    "    </center>\n",
    "<figure/>"
   ],
   "id": "7464b37709309c50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T08:19:05.504562Z",
     "start_time": "2024-05-18T08:19:05.488636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.array([1, 2, 3, 4]).reshape(-1, 1)\n",
    "b = np.array([1, 2, 3]).reshape(1, -1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
   ],
   "id": "38c70fa2247f0979",
   "execution_count": 38,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "这是您上面构建的密集层中的场景。将一维向量$b$添加到`(m,j)`矩阵。\n",
    "\n",
    "<figure>\n",
    "    <img src=\"../../images/C2_W1_Assign1_BroadcastMatrix.png\" alt='missing' width=\"740\">\n",
    "    <center>\n",
    "        <figcaption>\n",
    "            <b>\n",
    "                矩阵加一维向量\n",
    "            </b>\n",
    "        </figcaption>\n",
    "    </center>\n",
    "<figure/>"
   ],
   "id": "9dae6715d9e229e9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
